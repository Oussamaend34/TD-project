Diabetic Retinopathy (DR) is a high blood sugar level that causes damage to blood vessels and is one of the common causes of blindness in the developed world. Convolutional Neural Networks (CNNs) are one of the fundamental and successful applications of computer vision application, especially in prediction of DR. Recently self-attention has become a recent advance part of models that must capture long-range interactions. In this study, we propose a self-attention mechanism combined with pre-trained convolutions models in this case MobileNet. Self-attention is used to determine how much attention should pay to across Optical Coherence Tomography (OCT) image regions will modeling long-range, multi-level dependencies in order to accurately predict patient with DR. In the interest of demonstrating the feasibility of our method, we used Gradient-weighted Class Activation Mapping (Grad-CAM) to highlight important regions in the OCT used for prediction. Different metrics are used to evaluate the proposed model performance such as Accuracy, Recall, Precision, and Roc Area. The proposed architecture achieved 98% accuracy, 98% precision, and 98% recall.