The use of artificial intelligence (AI) in the healthcare field is gaining popularity. However, it also raises some concerns related to privacy and ethical aspects that require the development of a responsible AI framework. The principle of responsible AI states that artificial intelligence-based systems should be considered a part of composite societal and technological systems. This study attempts to establish whether AI risks in digital healthcare are positively associated with responsible AI. The moderating effect of perceived trust and perceived privacy risks is also examined. The theoretical model was based on perceived risk theory. Perceived risk theory is important in the context of this study, as risks related to uneasiness and uncertainty can be expected in the development of responsible AI due to the volatile nature of intelligent applications. Our research provides some interesting findings which are presented in the discussion section.